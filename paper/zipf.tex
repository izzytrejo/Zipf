\documentclass[a4paper,10pt]{article}

%%% USEPACKAGES %%%



%% \usepackage{fontspec}
%% 	\setmainfont{DejaVu Sans}

\usepackage[authoryear,round,sort]{natbib}
\usepackage[german,french,russian,english]{babel}
\usepackage{textgreek}

\usepackage[margin=0.75in]{geometry}

\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{setspace}
	\onehalfspacing
\usepackage{float}

\usepackage[usenames,dvipsnames,svgnames,table,xcdraw]{xcolor}
\usepackage[font=small,labelfont=bf, labelformat=brace, labelsep=space]{caption}

\usepackage{lipsum}
\usepackage{lscape}

\usepackage{url}
\usepackage{listings}




\usepackage{hyperref}
\hypersetup{
	colorlinks,
	linkcolor={red!95!blue},
	citecolor={Cerulean!75!black},
	urlcolor={blue!80!black},
	linktoc=page
}
\usepackage[all]{nowidow}
\widowpenalty10000
\clubpenalty10000
\usepackage{multicol}

\setlength{\abovecaptionskip}{5pt plus 3pt minus 2pt} 
\setlength{\belowcaptionskip}{5pt plus 3pt minus 2pt} 


\newenvironment{boxed}[1]
{\begin{center}
		#1\\[1ex]
		\begin{tabular}{|p{0.9\textwidth}|}
			\hline\\
		}
		{ 
			\\\\\hline
		\end{tabular} 
	\end{center}
}

\newcounter{code}[section]
\newenvironment{code}[1][]{\refstepcounter{code}\par\medskip
	\noindent \textbf{OxCal~Code~\thecode. #1} \rmfamily}{\medskip}

%%% ----- OPENING -----

\title{An Analysis of Zipf's law of Frequency Distribution Across Different Languages}

%% \author{Isabella Trejo\textsuperscript{1,2,*}\\
%% 	\small{\textsuperscript{*}Corresponding author: Isabellaluztrejo@gmail.com}}\\
\author{Isabella Trejo}

\date{\normalsize{Manuscript: \textit{Radiocarbon} (\today)}}

\begin{document}

\maketitle

%%% ----- ABSTRACT -----

\begin{abstract}
	Zipf’s law was coined in 1949 by George Zipf himself. The empirical law stated that the second most common term of a text is used half as much as the most common term, and the third most common term is used a third as much as the most common term, and so on. In order to analyze Zipf’s law of frequency distribution, I had to program a word frequency distribution calculator. The question being asked here was not solely if Zipf’s law applies in a given text, but if it applies in different languages. After analyzing and processing copies of The Odyssey and The Iliad in French, Spanish, Latin, Greek, and English,I found that  
\end{abstract}

%%% ----- KEYWORDS -----

\paragraph*{Keywords:} Zipf's law, frequency distribution

%%% ----- MAIN -----
\section{Introduction}

%--- FIND LOCATION ---

Linguistic analysis is the analysis of literature and its structure. The idea is to focus on the language itself, rather than its subject matter. “The study describes the unconscious rules and processes that speakers of a language use to create spoken or written language…” It can be useful to study linguistic analysis for those who want to learn a language or translate from one language to another. “The drive behind linguistic analysis is to understand and describe the knowledge that underlies the ability to speak a given language, and to understand how the human mind processes and creates language.” Understanding the cultural and grammatical laws to speech are fundamental to a language and its’ people Knowing and analyzing language structure helps people better understand one another. \citep[e.g.,][]{Talamo2016,ConardETAL2004-Vogelherd-14C-humans,TrinkausETAL2005,DevieseETAL2017-14C-Vindija, DaviesETAL2015-trans-mosaic,StreetETAL2006-fossil-record}.  \citep[e.g.][]{FuETAL2014-Ust-Ishim,FuETAL2015-Oase}. (\autoref{fig:map}).   \citep[][p.75]{Kaminska2014-Slov-Pal-Meso}. 


\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{../scripts/plot_Spanish_The_Odyssey.png}
	\caption{Map showing location of Šal’a (star) and sites with Neanderthal remains referenced in this paper: 1 -- Les Rochers-de-Villeneuve, 2 -- Ferassie (France), 3 -- Spy (Belgium), 4 --Kleine Feldhöfergrotte (Germany), 5 -- Vindija (Croatia), 6 -- Gánovce (Slovakia), 7 -- Mezmaiskaya (Russia). The site of Okladnikov is in the Altai Mountains (Russia) and not shown on the map due to its location further east.}
	\label{fig:map}
\end{figure}

%--- FIND DESCRIPTION AND PREVIOUS WORK ---

\subsection{Background}



Conversation opened. 1 unread message.

Skip to content
Using Gmail with screen readers
Enable desktop notifications for Gmail.   OK  No thanks
1 of 15
missing text
Inbox
Mark Galassi
	
2:05 PM (0 minutes ago)
	
to me

There are many natural laws derived from linguistic analysis, some that only apply to language, and some that apply to anything and everything. Inside the field of linguistic analysis is quantum linguistics. “Quantum linguistics refers to the multidimensional aspect of our thought processes and how that multidimensionality is represented to the outside world through our language.” Quantum linguistics begs the question, “What is part of the concept and what is not part of the concept?” George Kingsley Zipf was an American linguist who studied quantum linguistics in the 1900’s. Although the law was named after him, he was not the first to notice its occurrences. The French stenographer Jean-Baptiste Estoup and German physist Felix Auerbach also noted the same law around 10-30 years prior to Zipf.   




\section{Zipf's Law}

Zipf’s law was formulated using mathematical statistics refering to the fact that for many types of data studied in  physical and social sciences, the rank-frequency distribution is an inverse relation.  Zipf's law was originally formulated in terms of quantitative linguistics, stating that given a body of natural words, the frequency of any word is inversely proportional to its rank in the frequency table.  It states the most used word in a language is used twice as much as the second most used word, and three times as much as the third, etc. If the most frequent term occurs x amount of times, the second most frequent term has half as many occurrences, and the third most frequent term has a third as many occurrences, and so on.  What this means in practice is that very few word types account for the vast majority of the word occurrences (or tokens) in your collection of documents. There are a few key components of Zipf’s law that distinguish it from others.
• Frequency decreases very rapidly with rank
• The frequency of the word is inversely proportional to their ranks
• It’s an empirical law that holds in different languages and texts. 
• There’s a lot of interesting theories about why it should hold
• Zipf's law and Heaps' law often appear together.
• it is expected that distributions that follow Benford’s law should also follow Zipf’s law



\subsection{Usages}

• Used most in Natural Language Processing algorithm and in the Text Compression. 
• Used to generate the AI powered text that looks like a natural text and contains the words that a normal human use
• Used to distinguish between authentic data and fake data
• Statistical testing, 
• Used for extraction of parallel fragments of texts out of comparable corpora.
• Used by Laurance Doyle and others at the SETI institute as part of the search for extraterrestrial intelligence ow did they use Zipf’s law?
• The basic idea of Zipf’s law is useful in schemes for data compression and in allocation of resources by urban planners.
• The same relationship occurs in many other rankings of human-created systems, such as the ranks of mathematical expressions or ranks of notes in music, and even in uncontrolled environments, such as corporation sizes, income rankings, ranks of number of people watching the same TV channel, cells' transcriptomes  and so on. The appearance of the distribution in rankings of cities by population was first noticed by Felix Auerbach in 1913, leading to a broad literature of Zipf's law for cities. However, more recent empirical and theoretical studies have challenged the relevance of Zipf's law for cities.
• ndividual writing styles can be detected quite accurately by focusing on just these high-frequency low-semantically valuable words, which are what we are referring to when we use the term “stop words.”  Every person carries around little behavioral ticks that come across in these little words that are used all the time.

\subsection{Importance}

Zipf’s law is the calculation of frequency distribution. It is the ranking of the most frequently used term or data set. Recording the repeated words of a text can help people remember what topics are being discussed and what information is important. It takes the idea of an abstract, but allows a computer to do that analyzation without human assistance.
Zipf’s law articulates how much recycling of language people do. It is a question that further looks into human vocabulary, and leads to other philosophical questions. Why do people use the same word sover and over again when there are hundreds of thousands to choose from in the english language alone. What’s more, is this law of distribution does not work the same in all languages. There is a language barrier where certain filler words such as, “ the, and, of, it…” are given high meaning in certain languages, and are disregarded completely in others. This finding brings us down to the structural  creation of language, and its’ division based on geography. (expand on this hella) Why is the given so much meaning in English language?



\section{Methods}

There are many ways to go about finding the frequency distribution of words. However, there are certain steps that must be taken no matter what the code looks like. 

\subsection{Choosing datasets}


\subsection{Parsing Text}

Parsing text is the cleaning of text, so it may be further analyzed. Researchers do this in order to remove any extra items that aren’t needed in the dataset they are analyzing. 
-  If needed, remove unecessary footer and header
- Tokenize by words
- Tokenize by blank space
- Remove all punctuation
- If needed, remove stop words

\subsection{Finding the Frequency Distribution}

\section{Results}

After analyzing translations of The Odyssey and The Iliad in Latin, English, French, Spanish, and Greek, there have been a few conclusions that can be drawn, some of which apply to one another and some that are unique to each language.
- Zipf’s law only applies when counting in stop words
- The word, “the” hold more value in certain languages than it does others.
- For the most part, Zipf’s law applies to each language listed above.



\subsection{Causes}

Using the key-hole drilling technique, Šal'a I was sampled for \%N (5~mg) and aDNA (85~mg)


\subsubsection{Principle of Least Effort}

There is one explanation that Zipf himself proposed, and that is the principle of least effort. The principle of least effort is a broad theory which suggests that animals, people, and even well-designed machines will naturally choose the path of least resistance or "effort". In the late 1940’s, Zipf studied this law. In that decade he published a book titled, “Human Behaviour and the Principle of Least Effort: An Introduction to Human Ecology”. He proposed that neither speakers nor hearers using a given language want to work any harder than necessary to reach understanding, and the process that results in approximately equal distribution of effort leads to the observed. He theorized that the distribution of word use was due to tendency to communicate efficiently with least effort, also known as Zipf’s law.












\section{Discussion}

\subsection{Problems with Zipf's Law}

When looking at a table distribution of Zipf’s la the most frequently used words fall on the left side, and because words on the left side of your graph occur very frequently and words on the right very infrequently. The most frequently used terms carry a lot more information from a mathematical point of view. However, it carries a lot less information from a semantic point of view. “The,” “and,” and “of,” are not the most interesting words. If your question is about what makes documents different at the level of content or theme, then these words won’t tell you what you want to know. If one is analyzing text using Zipf’s law to extract the theme of the paper, they will go no where.
• Zipf's law for words suffers from three main problems: its formulation is ambiguous, its validity has not been tested rigorously from a statistical point of view, and it has not been confronted to a representatively large number of texts.
• Makes most frequent errors for highest frequency and lowest frequency words 
• It has been analyzed in more than 30,000 English texts. The goodness of fit tests yield that only about 15% of the texts are statistically compatible with this form of Zipf's law.


\section{Conclusions}

We successfully radiocarbon dated Šal'a I to >44,800~BP (OxA-X-2731-16) and Šal'a II to >45,100~BP (OxA-X-2731-15). Nonetheless, the successful collagen and hydroxyproline extraction did not translate to sufficiently preserved DNA for analysis. Therefore, we conclude that both Neanderthal individuals firmly belong to the Middle Paleolithic, and predate late Neanderthals (e.g., from Vindija and possibly Spy) as well as early AMHs in the region.


\section*{Acknowledgments}

This research has received funding from the European Research Council under the European Union’s Seventh Framework Programme (FP7/2007-2013) / ERC grant agreement no. 324139 PalaeoChron awarded to Professor Tom Higham. The publication process was facilitated by the Hunt Fellowship granted to Rachel J.A.~Hopkins by the Wenner Gren Foundation (Gr.~9881), and some of the travel expenses were covered by Wolfson College, Oxford. We would further like to thank Sarah Nagel and Birgit Nickel for their help in ancient DNA laboratory. The ancient DNA work was funded by the Max Planck Society and the European Research Council (grant agreement no. 694707 to Svante Pääbo). Additionally, none of this research would have been possible without the support of Mgr. Ján Kautman (Director of the Slovak National Museum -- Natural History Museum, Bratislava) and Dr. Matej Ruttkay (Director of the Institute of Archaeology, Slovak Academy of Sciences, Nitra), who gave us permission to sample Šal'a I and Šal'a II, respectively. We would also like to 


%%% ----- BIBLIOGRAPHY -----

\bibliographystyle{apalike} 
\bibliography{BIBLIO_Zipf} 



\end{document}
